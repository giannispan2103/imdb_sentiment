{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ProjectedAttentionTextRNN, TextRNN, AttentionTextRNN, TextSummaryRNN, ProjectedTextRNN\n",
    "from preprocess import generate_data\n",
    "from utils import train\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_text():\n",
    "    data = generate_data(emb_size=300, max_len=500)\n",
    "    emb_matrix = data['emb_matrix']\n",
    "    train_batches = data['train_batches']\n",
    "    test_batches = data['test_batches']\n",
    "    model = ProjectedAttentionTextRNN(emb_matrix, stacked_layers=1).cuda()\n",
    "    optimizer = Adam(model.params, 0.001)\n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    train(model, train_batches, test_batches, optimizer, criterion, 50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with: train - pos\n",
      "finished with: train - neg\n",
      "finished with: test - pos\n",
      "finished with: test - neg\n",
      "reviews for training: 27142\n",
      "reviews for testing: 25000\n",
      "tokens found in training data set: 130806\n",
      "tokens with frequency >= 1: 130806\n",
      "embedded tokens with frequency >= 1: 76329\n",
      "no embedding for:  *$*PAD*$*\n",
      "no embedding for:  *$*UNK*$*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\Python Scripts\\imdb_sentiment\\modules.py:193: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_weights = self.at_softmax(att_sc_dist).unsqueeze(2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, f1: 85.347 accuracy: 85.208 auc: 92.625. Time: 0 minutes, 15 seconds\n",
      "epoch 2, f1: 87.246 accuracy: 87.136 auc: 94.251. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 3, f1: 87.871 accuracy: 87.860 auc: 94.787. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 4, f1: 88.176 accuracy: 87.980 auc: 94.964. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 5, f1: 88.353 accuracy: 88.184 auc: 95.141. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 6, f1: 88.814 accuracy: 88.628 auc: 95.373. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 7, f1: 88.768 accuracy: 88.624 auc: 95.401. Time: 0 minutes, 15 seconds\n",
      "epoch 8, f1: 88.925 accuracy: 88.704 auc: 95.475. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 9, f1: 88.724 accuracy: 88.600 auc: 95.420. Time: 0 minutes, 15 seconds\n",
      "epoch 10, f1: 89.096 accuracy: 88.972 auc: 95.516. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 11, f1: 89.226 accuracy: 89.100 auc: 95.580. Time: 0 minutes, 16 seconds\n",
      "best epoch so far\n",
      "epoch 12, f1: 89.359 accuracy: 89.316 auc: 95.597. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 13, f1: 89.144 accuracy: 88.964 auc: 95.541. Time: 0 minutes, 15 seconds\n",
      "epoch 14, f1: 89.173 accuracy: 88.996 auc: 95.619. Time: 0 minutes, 15 seconds\n",
      "epoch 15, f1: 89.286 accuracy: 89.208 auc: 95.600. Time: 0 minutes, 15 seconds\n",
      "epoch 16, f1: 89.480 accuracy: 89.308 auc: 95.680. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 17, f1: 89.491 accuracy: 89.480 auc: 95.774. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 18, f1: 89.562 accuracy: 89.444 auc: 95.648. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 19, f1: 89.666 accuracy: 89.592 auc: 95.701. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 20, f1: 89.478 accuracy: 89.364 auc: 95.740. Time: 0 minutes, 15 seconds\n",
      "epoch 21, f1: 89.680 accuracy: 89.544 auc: 95.653. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 22, f1: 89.848 accuracy: 89.720 auc: 95.807. Time: 0 minutes, 15 seconds\n",
      "best epoch so far\n",
      "epoch 23, f1: 89.513 accuracy: 89.348 auc: 95.704. Time: 0 minutes, 15 seconds\n",
      "epoch 24, f1: 89.672 accuracy: 89.548 auc: 95.644. Time: 0 minutes, 15 seconds\n",
      "epoch 25, f1: 89.795 accuracy: 89.676 auc: 95.780. Time: 0 minutes, 16 seconds\n",
      "epoch 26, f1: 89.807 accuracy: 89.732 auc: 95.706. Time: 0 minutes, 15 seconds\n",
      "epoch 27, f1: 89.792 accuracy: 89.728 auc: 95.738. Time: 0 minutes, 15 seconds\n"
     ]
    }
   ],
   "source": [
    "run_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
